{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project ToDo List: Week 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore LDA with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ethanpotthoff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download NLTK stopwords\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Preprocess Data\n",
    "\n",
    "Kaggle Dataset:\n",
    "https://www.kaggle.com/datasets/abisheksudarshan/topic-modeling-for-research-articles?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>Computer Science</th>\n",
       "      <th>Mathematics</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Statistics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fundamental frequency (f0) approximation from ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this large-scale study, consisting of 24.5 mil...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we present a stability analysis of the plane c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>we construct finite time blow-up solutions to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>planetary nebulae (pne) constitute an importan...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            ABSTRACT  Computer Science  \\\n",
       "0  fundamental frequency (f0) approximation from ...                 0   \n",
       "1  this large-scale study, consisting of 24.5 mil...                 1   \n",
       "2  we present a stability analysis of the plane c...                 0   \n",
       "3  we construct finite time blow-up solutions to ...                 0   \n",
       "4  planetary nebulae (pne) constitute an importan...                 0   \n",
       "\n",
       "   Mathematics  Physics  Statistics  \n",
       "0            0        0           1  \n",
       "1            0        0           1  \n",
       "2            0        1           0  \n",
       "3            1        0           0  \n",
       "4            0        1           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv(\"project_data/Test.csv\", usecols = ['ABSTRACT','Computer Science', 'Mathematics', 'Physics', 'Statistics'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['fundamental', 'frequency', 'approximation', 'polyphonic', 'music', 'includes', 'tasks', 'multiple', 'melody', 'vocal', 'bass', 'line', 'estimation', 'historically', 'problems', 'approached', 'separately', 'recently', 'help', 'learning', 'based', 'approaches', 'present', 'multitask', 'deep', 'learning', 'architecture', 'jointly', 'estimates', 'outputs', 'considering', 'various', 'tasks', 'including', 'multiple', 'melody', 'vocal', 'bass', 'line', 'estimation', 'trained', 'help', 'large', 'semi', 'automatically', 'annotated', 'dataset', 'show', 'multitask', 'model', 'outperforms', 'single', 'task', 'counterparts', 'explore', 'effect', 'various', 'design', 'decisions', 'inside', 'approach', 'show', 'performs', 'better', 'least', 'competitively', 'compared', 'strong', 'baseline', 'methods']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize words and clean text using Gensim's simple_preprocess(). deacc=True removes punctuation.\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "        \n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "data = df.ABSTRACT.values.tolist()\n",
    "data_words = list(sent_to_words(data))\n",
    "data_words = remove_stopwords(data_words)\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 2), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 2), (33, 1), (34, 2), (35, 2), (36, 1), (37, 1), (38, 2), (39, 2), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 2), (51, 1), (52, 1), (53, 1), (54, 2), (55, 1), (56, 2), (57, 2)]]\n"
     ]
    }
   ],
   "source": [
    "# calculate word frequencies (mapped generated word ids to word frequencies) - to access word an id represents, call dictionary[id]\n",
    "# create Gensim Dictionary\n",
    "dictionary = corpora.Dictionary(data_words)\n",
    "\n",
    "# create corpus\n",
    "corpus = [dictionary.doc2bow(word) for word in data_words]\n",
    "\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('annotated', 1),\n",
       "  ('approach', 1),\n",
       "  ('approached', 1),\n",
       "  ('approaches', 1),\n",
       "  ('approximation', 1),\n",
       "  ('architecture', 1),\n",
       "  ('automatically', 1),\n",
       "  ('based', 1),\n",
       "  ('baseline', 1),\n",
       "  ('bass', 2),\n",
       "  ('better', 1),\n",
       "  ('compared', 1),\n",
       "  ('competitively', 1),\n",
       "  ('considering', 1),\n",
       "  ('counterparts', 1),\n",
       "  ('dataset', 1),\n",
       "  ('decisions', 1),\n",
       "  ('deep', 1),\n",
       "  ('design', 1),\n",
       "  ('effect', 1),\n",
       "  ('estimates', 1),\n",
       "  ('estimation', 2),\n",
       "  ('explore', 1),\n",
       "  ('frequency', 1),\n",
       "  ('fundamental', 1),\n",
       "  ('help', 2),\n",
       "  ('historically', 1),\n",
       "  ('includes', 1),\n",
       "  ('including', 1),\n",
       "  ('inside', 1),\n",
       "  ('jointly', 1),\n",
       "  ('large', 1),\n",
       "  ('learning', 2),\n",
       "  ('least', 1),\n",
       "  ('line', 2),\n",
       "  ('melody', 2),\n",
       "  ('methods', 1),\n",
       "  ('model', 1),\n",
       "  ('multiple', 2),\n",
       "  ('multitask', 2),\n",
       "  ('music', 1),\n",
       "  ('outperforms', 1),\n",
       "  ('outputs', 1),\n",
       "  ('performs', 1),\n",
       "  ('polyphonic', 1),\n",
       "  ('present', 1),\n",
       "  ('problems', 1),\n",
       "  ('recently', 1),\n",
       "  ('semi', 1),\n",
       "  ('separately', 1),\n",
       "  ('show', 2),\n",
       "  ('single', 1),\n",
       "  ('strong', 1),\n",
       "  ('task', 1),\n",
       "  ('tasks', 2),\n",
       "  ('trained', 1),\n",
       "  ('various', 2),\n",
       "  ('vocal', 2)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(dictionary[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Gensim LDA Model\n",
    "\n",
    "https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build LDA model with Gensim\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=4, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.025*\"inside\" + 0.018*\"considering\" + 0.011*\"network\" + 0.009*\"method\" + '\n",
      "  '0.009*\"networks\" + 0.009*\"learning\" + 0.008*\"algorithm\" + 0.008*\"sampling\" '\n",
      "  '+ 0.008*\"performance\" + 0.007*\"neural\" + 0.007*\"state\" + 0.007*\"algorithms\" '\n",
      "  '+ 0.007*\"system\" + 0.007*\"time\" + 0.006*\"computational\" + 0.006*\"propose\" + '\n",
      "  '0.006*\"problem\" + 0.005*\"based\" + 0.005*\"proposed\" + 0.005*\"control\"'),\n",
      " (1,\n",
      "  '0.034*\"inside\" + 0.028*\"considering\" + 0.012*\"hamiltonians\" + 0.010*\"monte\" '\n",
      "  '+ 0.009*\"hmc\" + 0.009*\"carlo\" + 0.008*\"hamiltonian\" + 0.007*\"metropolis\" + '\n",
      "  '0.007*\"sampling\" + 0.006*\"generalized\" + 0.006*\"mmhmc\" + 0.006*\"modified\" + '\n",
      "  '0.005*\"problem\" + 0.005*\"show\" + 0.005*\"algorithm\" + 0.005*\"paper\" + '\n",
      "  '0.005*\"dimensional\" + 0.004*\"two\" + 0.004*\"statistics\" + 0.004*\"linear\"'),\n",
      " (2,\n",
      "  '0.036*\"inside\" + 0.011*\"considering\" + 0.009*\"magnetic\" + 0.009*\"coupling\" '\n",
      "  '+ 0.009*\"field\" + 0.005*\"potential\" + 0.005*\"anisotropic\" + 0.005*\"nature\" '\n",
      "  '+ 0.005*\"momentum\" + 0.005*\"observed\" + 0.005*\"irreversible\" + '\n",
      "  '0.004*\"observations\" + 0.004*\"skx\" + 0.004*\"phase\" + 0.004*\"quantum\" + '\n",
      "  '0.004*\"mass\" + 0.004*\"theory\" + 0.004*\"energy\" + 0.004*\"spin\" + '\n",
      "  '0.004*\"two\"'),\n",
      " (3,\n",
      "  '0.036*\"inside\" + 0.020*\"considering\" + 0.017*\"data\" + 0.011*\"model\" + '\n",
      "  '0.010*\"method\" + 0.010*\"models\" + 0.008*\"methods\" + 0.006*\"based\" + '\n",
      "  '0.005*\"help\" + 0.005*\"learning\" + 0.005*\"paper\" + 0.004*\"used\" + '\n",
      "  '0.004*\"idea\" + 0.004*\"behind\" + 0.004*\"information\" + 0.004*\"propose\" + '\n",
      "  '0.004*\"different\" + 0.004*\"two\" + 0.004*\"image\" + 0.004*\"results\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics(num_words=20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation Metrics\n",
    "\n",
    "https://radimrehurek.com/gensim/models/coherencemodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.211530593778528\n",
      "\n",
      "Coherence Score:  0.4246014285352172\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "# https://radimrehurek.com/gensim/models/coherencemodel.html\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words, dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Conceptnet\n",
    "\n",
    "Using Conceptnet API: https://github.com/commonsense/conceptnet5/wiki/API\n",
    "\n",
    "There are three methods for accessing data through the ConceptNet 5 API: lookup, search, and association.\n",
    "- __Lookup__ is for when you know the URI of an object in ConceptNet, and want to see a list of edges that include it.\n",
    "- __Search__ finds a list of edges that match certain criteria.\n",
    "- __Association__ is for finding concepts similar to a particular concept or a list of concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "obj = requests.get('http://api.conceptnet.io/c/en/dog').json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['@context', '@id', 'edges', 'version', 'view'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@id': '/a/[/r/RelatedTo/,/c/en/dog/,/c/en/pet/]',\n",
       " '@type': 'Edge',\n",
       " 'dataset': '/d/verbosity',\n",
       " 'end': {'@id': '/c/en/pet',\n",
       "  '@type': 'Node',\n",
       "  'label': 'pet',\n",
       "  'language': 'en',\n",
       "  'term': '/c/en/pet'},\n",
       " 'license': 'cc:by/4.0',\n",
       " 'rel': {'@id': '/r/RelatedTo', '@type': 'Relation', 'label': 'RelatedTo'},\n",
       " 'sources': [{'@id': '/and/[/s/process/split_words/,/s/resource/verbosity/]',\n",
       "   '@type': 'Source',\n",
       "   'contributor': '/s/resource/verbosity',\n",
       "   'process': '/s/process/split_words'},\n",
       "  {'@id': '/s/resource/verbosity',\n",
       "   '@type': 'Source',\n",
       "   'contributor': '/s/resource/verbosity'}],\n",
       " 'start': {'@id': '/c/en/dog',\n",
       "  '@type': 'Node',\n",
       "  'label': 'dog',\n",
       "  'language': 'en',\n",
       "  'term': '/c/en/dog'},\n",
       " 'surfaceText': '[[dog]] is related to [[pet]]',\n",
       " 'weight': 9.82975075981075}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj['edges'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
