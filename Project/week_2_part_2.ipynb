{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ethanpotthoff/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/ethanpotthoff/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ethanpotthoff/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "from math import log\n",
    "from statistics import mean\n",
    "\n",
    "# import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Preprocess Data\n",
    "\n",
    "Kaggle Dataset:\n",
    "https://www.kaggle.com/datasets/abisheksudarshan/topic-modeling-for-research-articles?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"project_data/Test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk_sw = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def get_wordnet_tag(tag):\n",
    "    tag_map = {\n",
    "        \"J\": nltk.corpus.wordnet.ADJ,\n",
    "        \"N\": nltk.corpus.wordnet.NOUN,\n",
    "        \"V\": nltk.corpus.wordnet.VERB,\n",
    "        \"R\": nltk.corpus.wordnet.ADV\n",
    "    }\n",
    "    return tag_map.get(tag[0].upper(), nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens = nltk.RegexpTokenizer(\"[\\w']+\").tokenize(text)\n",
    "    tokens = nltk.pos_tag(tokens)\n",
    "    tokens = [nltk.stem.WordNetLemmatizer().lemmatize(word, get_wordnet_tag(tag)) for word, tag in tokens]\n",
    "    tokens = [word for word in tokens if word not in nltk_sw]\n",
    "    return tokens\n",
    "\n",
    "def get_corpus(docs):\n",
    "    return docs.apply(get_tokens)\n",
    "\n",
    "# docs must be a list of lists of words\n",
    "def get_stopwords(corpus, tfidf=False):\n",
    "    words = {}\n",
    "    for i, doc in enumerate(corpus):\n",
    "        for word in doc:\n",
    "            words[word] = words.get(word, {})\n",
    "            words[word][i] = (words[word].get(i, 0) + 1) if tfidf else 1\n",
    "\n",
    "    for word in words:\n",
    "        if tfidf:\n",
    "            tf = sum(words[word].values())\n",
    "            df = len(words[word].values())\n",
    "            tfidf = tf / df\n",
    "            words[word] = tfidf\n",
    "        else:\n",
    "            words[word] = len(words[word].values()) / len(corpus)\n",
    "    \n",
    "    s = pd.Series(words)\n",
    "    return s[s > .50].sort_values()\n",
    "\n",
    "def remove_corpus_stopwords(corpus):\n",
    "    sw = get_stopwords(corpus)\n",
    "    return corpus.apply(lambda tokens: [word for word in tokens if word not in sw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = df[\"ABSTRACT\"]\n",
    "corpus = remove_corpus_stopwords(get_corpus(docs))\n",
    "dictionary = gensim.corpora.Dictionary(corpus)\n",
    "word_freq = [dictionary.doc2bow(word) for word in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " 0.021*\"hamiltonians\" + 0.014*\"hamiltonian\" + 0.013*\"1\" + 0.012*\"n\" + 0.010*\"2\" + 0.009*\"k\" + 0.008*\"manifold\" + 0.008*\"equation\" + 0.008*\"result\" + 0.007*\"bound\" + 0.006*\"function\" + 0.006*\"problem\" + 0.006*\"show\" + 0.006*\"give\" + 0.006*\"solution\" + 0.006*\"p\" + 0.006*\"prove\" + 0.005*\"time\" + 0.005*\"case\" + 0.005*\"group\" \n",
      "\n",
      "1 \n",
      " 0.016*\"method\" + 0.014*\"model\" + 0.009*\"data\" + 0.008*\"sample\" + 0.008*\"algorithm\" + 0.008*\"propose\" + 0.008*\"network\" + 0.007*\"use\" + 0.006*\"problem\" + 0.006*\"base\" + 0.006*\"show\" + 0.005*\"learn\" + 0.005*\"result\" + 0.005*\"paper\" + 0.005*\"help\" + 0.005*\"performance\" + 0.004*\"system\" + 0.004*\"carlo\" + 0.004*\"monte\" + 0.004*\"time\" \n",
      "\n",
      "2 \n",
      " 0.013*\"0\" + 0.011*\"1\" + 0.010*\"mass\" + 0.009*\"2\" + 0.009*\"galaxy\" + 0.008*\"star\" + 0.006*\"5\" + 0.006*\"3\" + 0.006*\"find\" + 0.006*\"high\" + 0.005*\"10\" + 0.005*\"observation\" + 0.005*\"_\" + 0.005*\"present\" + 0.005*\"stellar\" + 0.004*\"gas\" + 0.004*\"low\" + 0.004*\"4\" + 0.004*\"model\" + 0.004*\"cluster\" \n",
      "\n",
      "3 \n",
      " 0.013*\"magnetic\" + 0.012*\"couple\" + 0.012*\"field\" + 0.011*\"momentum\" + 0.010*\"magnetocrystalline\" + 0.008*\"potential\" + 0.007*\"nature\" + 0.007*\"phase\" + 0.007*\"anisotropic\" + 0.007*\"result\" + 0.007*\"state\" + 0.007*\"crystallographic\" + 0.007*\"irreversible\" + 0.007*\"theory\" + 0.006*\"skx\" + 0.006*\"energy\" + 0.006*\"spin\" + 0.005*\"quantum\" + 0.005*\"lattice\" + 0.005*\"temperature\" \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=word_freq,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=4,\n",
    "                                            random_state=100,\n",
    "                                            update_every=1,\n",
    "                                            chunksize=100,\n",
    "                                            passes=10,\n",
    "                                            alpha=\"auto\",\n",
    "                                            per_word_topics=True)\n",
    "\n",
    "[print(row[0], '\\n', row[1], '\\n') for row in lda_model.print_topics(num_words=20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "def get_num_topics_per_word(lda_result, num_topics):\n",
    "    word_counts = {}\n",
    "    for topic in range(num_topics):\n",
    "        tokens = nltk.RegexpTokenizer(\"[\\w']+\").tokenize(lda_result[topic][1])\n",
    "        tokens = [x for x in tokens if not (x.isdigit() \n",
    "                                         or x[0] == '-' and x[1:].isdigit())]\n",
    "        for token in tokens:\n",
    "            if token in word_counts.keys():\n",
    "                word_counts[token] += 1\n",
    "            else:\n",
    "                word_counts[token] = 1\n",
    "                \n",
    "    return(dict(sorted(word_counts.items(), key=operator.itemgetter(1),reverse=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': 4,\n",
       " 'study': 3,\n",
       " 'model': 3,\n",
       " 'problem': 2,\n",
       " 'show': 2,\n",
       " 'time': 2,\n",
       " 'x': 2,\n",
       " 'also': 2,\n",
       " 'paper': 2,\n",
       " 'sample': 2,\n",
       " 'use': 2,\n",
       " 'help': 2,\n",
       " 'system': 2,\n",
       " 'two': 2,\n",
       " 'high': 2,\n",
       " 'present': 2,\n",
       " 'state': 2,\n",
       " 'hamiltonians': 1,\n",
       " 'hamiltonian': 1,\n",
       " 'n': 1,\n",
       " 'k': 1,\n",
       " 'manifold': 1,\n",
       " 'equation': 1,\n",
       " 'bound': 1,\n",
       " 'function': 1,\n",
       " 'give': 1,\n",
       " 'solution': 1,\n",
       " 'p': 1,\n",
       " 'prove': 1,\n",
       " 'case': 1,\n",
       " 'group': 1,\n",
       " 'space': 1,\n",
       " 'generalized': 1,\n",
       " 'riemann': 1,\n",
       " 'number': 1,\n",
       " 'metric': 1,\n",
       " 'obtain': 1,\n",
       " 'construction': 1,\n",
       " 'non': 1,\n",
       " 'g': 1,\n",
       " 'point': 1,\n",
       " 'q': 1,\n",
       " 'r': 1,\n",
       " 'u': 1,\n",
       " 'modified': 1,\n",
       " 'dimension': 1,\n",
       " 'c': 1,\n",
       " 'method': 1,\n",
       " 'data': 1,\n",
       " 'algorithm': 1,\n",
       " 'propose': 1,\n",
       " 'network': 1,\n",
       " 'base': 1,\n",
       " 'learn': 1,\n",
       " 'performance': 1,\n",
       " 'carlo': 1,\n",
       " 'monte': 1,\n",
       " 'test': 1,\n",
       " 'idea': 1,\n",
       " 'hmc': 1,\n",
       " 'image': 1,\n",
       " 'task': 1,\n",
       " 'behind': 1,\n",
       " 'achieve': 1,\n",
       " 'provide': 1,\n",
       " 'metropolis': 1,\n",
       " 'computational': 1,\n",
       " 'information': 1,\n",
       " 'well': 1,\n",
       " 'technique': 1,\n",
       " 'neural': 1,\n",
       " 'mass': 1,\n",
       " 'galaxy': 1,\n",
       " 'star': 1,\n",
       " 'find': 1,\n",
       " 'observation': 1,\n",
       " '_': 1,\n",
       " 'stellar': 1,\n",
       " 'gas': 1,\n",
       " 'low': 1,\n",
       " 'cluster': 1,\n",
       " 'spectrum': 1,\n",
       " 'formation': 1,\n",
       " 'survey': 1,\n",
       " 'dark': 1,\n",
       " 'z': 1,\n",
       " 'matter': 1,\n",
       " 'planet': 1,\n",
       " 'line': 1,\n",
       " 'spectral': 1,\n",
       " 'h': 1,\n",
       " 'large': 1,\n",
       " 'source': 1,\n",
       " 'emission': 1,\n",
       " 'ray': 1,\n",
       " 'magnetic': 1,\n",
       " 'couple': 1,\n",
       " 'field': 1,\n",
       " 'momentum': 1,\n",
       " 'magnetocrystalline': 1,\n",
       " 'potential': 1,\n",
       " 'nature': 1,\n",
       " 'phase': 1,\n",
       " 'anisotropic': 1,\n",
       " 'crystallographic': 1,\n",
       " 'irreversible': 1,\n",
       " 'theory': 1,\n",
       " 'skx': 1,\n",
       " 'energy': 1,\n",
       " 'spin': 1,\n",
       " 'quantum': 1,\n",
       " 'lattice': 1,\n",
       " 'temperature': 1,\n",
       " 'observe': 1,\n",
       " 'investigate': 1,\n",
       " 'order': 1,\n",
       " 'change': 1,\n",
       " 'crystal': 1,\n",
       " 'transition': 1,\n",
       " 'direction': 1,\n",
       " 'orientation': 1,\n",
       " 'angle': 1,\n",
       " 'new': 1,\n",
       " 'density': 1,\n",
       " 'resolve': 1,\n",
       " 'spectroscopy': 1,\n",
       " 'elastic': 1,\n",
       " 'light': 1,\n",
       " 'effect': 1}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = get_num_topics_per_word(lda_model.print_topics(num_words=40),4)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
